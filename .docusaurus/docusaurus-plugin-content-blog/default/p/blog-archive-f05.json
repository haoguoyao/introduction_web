{"archive":{"blogPosts":[{"id":"Testing","metadata":{"permalink":"/blog/Testing","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-04-01-optimizer.md","source":"@site/blog/2025-04-01-optimizer.md","title":"Optimizer choosing","description":"Recently I was working on a contract,.","date":"2025-04-01T00:00:00.000Z","tags":[],"readingTime":0.12,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"Testing","title":"Optimizer choosing"},"unlisted":false,"nextItem":{"title":"How AI designed differently or Dota2 and StarCraft II","permalink":"/blog/2024/07/28/starcraftdota"}},"content":"Recently I was working on a contract,.\n\nIt shows that the Adam optimizer perform betters is we train the model from scratch, and the"},{"id":"/2024/07/28/starcraftdota","metadata":{"permalink":"/blog/2024/07/28/starcraftdota","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-07-28-starcraftdota.md","source":"@site/blog/2024-07-28-starcraftdota.md","title":"How AI designed differently or Dota2 and StarCraft II","description":"Go is considered to be the most complex board game. But video games could be more complex that Go.","date":"2024-07-28T00:00:00.000Z","tags":[],"readingTime":2.665,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Optimizer choosing","permalink":"/blog/Testing"}},"content":"Go is considered to be the most complex board game. But video games could be more complex that Go.\nAlphaGo beat human at 2016, but Dota2 and Starcraft2 were not solved until 2019.\n\n|         | **Go**                          | **StarCraft II**                       | **Dota 2**                              |\n|------------------------|----------------------------------|----------------------------------------|------------------------------------------|\n| **Game Type**          | Turn-based, 1v1                 | Real-time, 1v1               | Real-time team game, 5v5                 |\n| **Information**        | Fully observable                | Partially observable (fog of war)     | Partially observable (fog of war)       |\n| **Action Space**       | ~250 discrete moves             | Thousands of actions | Thousands of actions|\n| **Time Horizon**       | ~150 moves                      | 20,000+ ticks per game                | 20,000+ ticks per game                   |\n| **Temporal Nature**    | Turn-based                      | Real-time                             | Real-time                                |\n| **Control Complexity** | One move at a time              | Hundreds of units           | One hero per agent, team synergy         |\n| **Collaboration**      | Single-agent                    | Single-agent                          | Multi-agent coordination                 |\n\n---\n\nIn recent years, **AlphaStar** (by DeepMind) and **OpenAI Five** (by OpenAI) have stood out as groundbreaking AI systems that defeated top human players in some of the most complex real-time strategy games: **StarCraft II** and **Dota 2**.\n\n\nThis post will walk you through **how AlphaStar and OpenAI Five handle time** differently.\n---\n\n##  AlphaStar: Transformers on a Single Snapshot\n\nAlphaStar processes the game **frame by frame**.\n\n### Input:\nAt each time step, AlphaStar takes a **set of entities** (e.g., units, buildings, etc.), where each entity is represented by features like health, position, type, etc. This forms a **structured input sequence** — not in time, but in space.\n\n### Architecture:\n- A **Transformer encoder** processes this unordered list of entities.\n- **Self-attention** allows the model to understand relationships between units (e.g., who is attacking whom, who’s in danger).\n- A **Pointer Network** is used for output to select actions targeting specific entities or positions.\n\n>  AlphaStar doesn’t model time explicitly — **each frame is processed independently**. Temporal understanding must be inferred indirectly through state variables like cooldown timers or health deltas.\n\n---\n\n##  OpenAI Five: LSTM Over Time\n\nIn contrast, OpenAI Five **models a sequence of time steps**.\n\n### Input:\nEvery agent (one per hero) observes the environment **every 4 frames**, resulting in **a long sequence of observations** — up to 20,000 steps in a full match.\n\n### Architecture:\n- A **single-layer LSTM** with 1024 hidden units captures the agent’s past observations and actions.\n- This allows the agent to **remember previous events**, such as skill usage, movement patterns, or enemy behavior.\n\n>  OpenAI Five relies heavily on explicit memory. It passes and updates the `hidden_state` between steps, allowing the AI to form **temporal context** and learn long-horizon strategies.\n\n## Why the design differ between AlphaStar and OpenAI Five\n\nThe two games require different types of intelligence:\n\n- **StarCraft II** (AlphaStar):\n  - Heavy emphasis on **multi-unit spatial micromanagement**.\n  - Needs to understand \"who is doing what\" in the current frame.\n  - Time can be indirectly inferred from unit states (e.g., cooldowns).\n  - Transformer excels at modeling **relations between entities**.\n\n- **Dota 2** (OpenAI Five):\n  - Involves **long-horizon team strategies** and skill combos.\n  - Agents need memory of past actions, enemy sightings, map control.\n  - LSTM is better suited for capturing **sequential decision patterns**."}]}}